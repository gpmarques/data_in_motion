{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    generator_input = keras.Input(shape=(256, 256, 1))\n",
    "    \n",
    "    x = layers.Conv2D(16, kernel_size=4, strides=2, padding='same')(generator_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(32, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(64, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(128, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(1, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "\n",
    "    x = layers.Dense(8*16*16*128)(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Reshape((8, 16, 16, 128))(x)\n",
    "\n",
    "    x = layers.Conv3DTranspose(64, kernel_size=4, strides=2 , padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv3DTranspose(32, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv3DTranspose(16, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = layers.Conv3DTranspose(1, kernel_size=4, strides=(1,2,2), activation='tanh', padding='same')(x)\n",
    "\n",
    "    generator = keras.models.Model(generator_input, x)\n",
    "    print(generator.summary())\n",
    "    \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    discriminator_input = keras.Input(shape=(64, 256, 256, 1))\n",
    "\n",
    "    y = layers.Conv3D(16, kernel_size=4, strides=2, padding='same')(discriminator_input)\n",
    "    y = layers.LeakyReLU()(y)\n",
    "\n",
    "    y = layers.Conv3D(32, kernel_size=4, strides=2, padding='same')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.LeakyReLU()(y)\n",
    "\n",
    "    y = layers.Conv3D(64, kernel_size=4, strides=2, padding='same')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.LeakyReLU()(y)\n",
    "\n",
    "    y = layers.Conv3D(1, kernel_size=4, strides=2, padding='same')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.LeakyReLU()(y)\n",
    "\n",
    "    y = layers.Flatten()(y)\n",
    "    y = layers.Dropout(0.4)(y)\n",
    "    y = layers.Dense(1, activation=\"sigmoid\")(y)\n",
    "\n",
    "    discriminator = keras.models.Model(discriminator_input, y)\n",
    "    print(discriminator.summary())\n",
    "    \n",
    "    return discriminator    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 256, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 16)      272       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        8224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 64)        32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 1)           2049      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 1)           4         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 262144)            17039360  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 262144)            0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 16, 16, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_1 (Conv3DTr (None, 16, 32, 32, 64)    524352    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 32, 32, 64)    256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16, 32, 32, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_2 (Conv3DTr (None, 32, 64, 64, 32)    131104    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 64, 64, 32)    128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 64, 64, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_3 (Conv3DTr (None, 64, 128, 128, 16)  32784     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 64, 128, 128, 16)  64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 64, 128, 128, 16)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_4 (Conv3DTr (None, 64, 256, 256, 1)   1025      \n",
      "=================================================================\n",
      "Total params: 17,904,614\n",
      "Trainable params: 17,903,908\n",
      "Non-trainable params: 706\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64, 256, 256, 1)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 32, 128, 128, 16)  1040      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 32, 128, 128, 16)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 16, 64, 64, 32)    32800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 64, 64, 32)    128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 16, 64, 64, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 8, 32, 32, 64)     131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 8, 32, 32, 64)     256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 8, 32, 32, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 4, 16, 16, 1)      4097      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 4, 16, 16, 1)      4         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 4, 16, 16, 1)      0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 170,486\n",
      "Trainable params: 170,292\n",
      "Non-trainable params: 194\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defun gives 10 secs/epoch performance boost\n",
    "generator.call = tf.contrib.eager.defun(generator.call)\n",
    "discriminator.call = tf.contrib.eager.defun(discriminator.call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, generated_output):\n",
    "    # [1,1,...,1] with real output since it is true and we want\n",
    "    # our generated examples to look like it\n",
    "    real_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.ones_like(real_output), logits=real_output)\n",
    "\n",
    "    # [0,0,...,0] with generated images since they are fake\n",
    "    generated_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.zeros_like(generated_output), logits=generated_output)\n",
    "\n",
    "    total_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(input_frames, generated_output):\n",
    "    distance_L1 = tf.reduce_sum(tf.abs(tf.subtract(input_frames, generated_output[:, 0])))\n",
    "    return tf.losses.sigmoid_cross_entropy(tf.ones_like(generated_output), generated_output) + (distance_L1*0.0008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "generator_optimizer = tf.train.AdamOptimizer(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_first_frames(first_frames):\n",
    "\n",
    "    fig = plt.figure(figsize=(256,256))\n",
    "  \n",
    "    for i in range(20):\n",
    "        plt.subplot(256, 256, i+1)\n",
    "        print(type(first_frames[i].eval(session=sess)))\n",
    "        plt.imshow(np.asarray(first_frames[i] * 127.5 + 127.5, dtype='float32'), cmap='gray')\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run input_pipeline.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If your data is in the form of symbolic tensors, you should specify the `steps` argument (instead of the `batch_size` argument, because symbolic tensors are expected to produce batches of input data).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-248b3186690f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mgen_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch_of_initial_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_videos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgen_tape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mgenerated_videos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mreal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_videos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    243\u001b[0m                                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                                     \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                                     steps_name='steps')\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_num_samples\u001b[0;34m(ins, batch_size, steps, steps_name)\u001b[0m\n\u001b[1;32m    567\u001b[0m             raise ValueError(\n\u001b[1;32m    568\u001b[0m                 \u001b[0;34m'If your data is in the form of symbolic tensors, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m                 \u001b[0;34m'you should specify the `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msteps_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'` argument '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m                 \u001b[0;34m'(instead of the `batch_size` argument, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m                 \u001b[0;34m'because symbolic tensors are expected to produce '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: If your data is in the form of symbolic tensors, you should specify the `steps` argument (instead of the `batch_size` argument, because symbolic tensors are expected to produce batches of input data)."
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import skvideo.io\n",
    "\n",
    "save_dir = '/../../../../newvolume/gen_videos'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    batch_videos = sess.run(next_batch)\n",
    "    gen_input = get_batch_of_initial_frames(batch_videos)\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_videos = generator.predict(gen_input)\n",
    "\n",
    "        real_output = discriminator.train_on_batch(batch_videos)\n",
    "        generated_output = discriminator.train_on_batch(generated_videos)\n",
    "\n",
    "        gen_loss = generator_loss(gen_input, generated_output)\n",
    "        disc_loss = discriminator_loss(real_output, generated_output)    \n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.variables))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        discriminator.save_weights('discriminator_3.h5')\n",
    "        generator.save_weights('generator_3.h5')\n",
    "        print(epoch)\n",
    "        print('discriminator loss:', sess.run(disc_loss))\n",
    "        print('adversarial loss:', sess.run(gen_loss))\n",
    "        np_gen_videos = np.asarray(generated_videos.eval())\n",
    "        #         display_first_frames(tf.unstack(generated_videos[:, 0]))\n",
    "        show_sample(np_gen_videos[0][0].reshape(256, 256), np_gen_videos[10][16].reshape(256, 256))\n",
    "        for i in range(20):\n",
    "            video = ((np_gen_videos[i] - np_gen_videos[i].min()) * (1/(np_gen_videos[i].max() - np_gen_videos[i].min()) * 255)).astype('uint8')\n",
    "            skvideo.io.vwrite(os.path.join(save_dir, \"generated_video_{}.mp4\".format(i)), video)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
